{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle as kg\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.layers import Input, Dense, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD,RMSprop,Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KAGGLE_USERNAME\"] = \"thasinkhan\"\n",
    "os.environ[\"KAGGLE_KEY\"] = \"d0e58b5e1972f61220788d36914159c2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.api.authenticate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/medahmedkrichen/devanagari-handwritten-character-datase\n"
     ]
    }
   ],
   "source": [
    "kg.api.dataset_download_files(dataset=\"medahmedkrichen/devanagari-handwritten-character-datase\",\n",
    "                              path=\"dataset\",unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_df(path):\n",
    "\n",
    "    img_path = list()\n",
    "    img_label = list()\n",
    "\n",
    "    for single_class_dir_path in pathlib.Path(path).glob(\"*\"):\n",
    "\n",
    "        for single_class_img_path in pathlib.Path(single_class_dir_path).glob(\"*.png\"):\n",
    "\n",
    "            img_path.append(str(single_class_img_path))\n",
    "            #print(str(single_class_img_path).split(\"/\")[-2].split(\"_\")[-1])\n",
    "            img_label.append(str(single_class_img_path).split(\"/\")[-2].split(\"_\")[-1])\n",
    "\n",
    "    return pd.DataFrame(data={\"img_path\":img_path,\"label\":img_label})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"dataset/DevanagariHandwrittenCharacterDataset/Train\"\n",
    "test_path = \"dataset/DevanagariHandwrittenCharacterDataset/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = train_test_df(train_path)\n",
    "testing_data = train_test_df(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((78200, 2), (13800, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape,testing_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset/DevanagariHandwrittenCharacterDataset/...</td>\n",
       "      <td>ra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset/DevanagariHandwrittenCharacterDataset/...</td>\n",
       "      <td>ra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset/DevanagariHandwrittenCharacterDataset/...</td>\n",
       "      <td>ra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset/DevanagariHandwrittenCharacterDataset/...</td>\n",
       "      <td>ra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset/DevanagariHandwrittenCharacterDataset/...</td>\n",
       "      <td>ra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path label\n",
       "0  dataset/DevanagariHandwrittenCharacterDataset/...    ra\n",
       "1  dataset/DevanagariHandwrittenCharacterDataset/...    ra\n",
       "2  dataset/DevanagariHandwrittenCharacterDataset/...    ra\n",
       "3  dataset/DevanagariHandwrittenCharacterDataset/...    ra\n",
       "4  dataset/DevanagariHandwrittenCharacterDataset/...    ra"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset/DevanagariHandwrittenCharacterDataset/...</td>\n",
       "      <td>ra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset/DevanagariHandwrittenCharacterDataset/...</td>\n",
       "      <td>ra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset/DevanagariHandwrittenCharacterDataset/...</td>\n",
       "      <td>ra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset/DevanagariHandwrittenCharacterDataset/...</td>\n",
       "      <td>ra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset/DevanagariHandwrittenCharacterDataset/...</td>\n",
       "      <td>ra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path label\n",
       "0  dataset/DevanagariHandwrittenCharacterDataset/...    ra\n",
       "1  dataset/DevanagariHandwrittenCharacterDataset/...    ra\n",
       "2  dataset/DevanagariHandwrittenCharacterDataset/...    ra\n",
       "3  dataset/DevanagariHandwrittenCharacterDataset/...    ra\n",
       "4  dataset/DevanagariHandwrittenCharacterDataset/...    ra"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ra', 'chha', 'patalosaw', 'dha', 'la', 'ga', 'yaw', 'na', '3',\n",
       "       'petchiryakha', 'pha', 'gya', 'da', 'kha', 'tha', '1', 'ja', '4',\n",
       "       'ma', 'motosaw', 'chhya', 'ha', '6', 'taamatar', '2', 'yna',\n",
       "       'adna', 'tra', 'kna', 'tabala', 'ba', 'waw', '7', 'pa', '0', 'jha',\n",
       "       'bha', 'daa', '9', '8', 'dhaa', 'gha', 'cha', 'thaa', 'ka', '5'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 46)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(len(training_data['label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "character2int = dict(zip(training_data[\"label\"].unique(),range(len(training_data[\"label\"].unique()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ra', 'chha', 'patalosaw', 'dha', 'la', 'ga', 'yaw', 'na', '3', 'petchiryakha', 'pha', 'gya', 'da', 'kha', 'tha', '1', 'ja', '4', 'ma', 'motosaw', 'chhya', 'ha', '6', 'taamatar', '2', 'yna', 'adna', 'tra', 'kna', 'tabala', 'ba', 'waw', '7', 'pa', '0', 'jha', 'bha', 'daa', '9', '8', 'dhaa', 'gha', 'cha', 'thaa', 'ka', '5'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character2int.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[\"label\"].replace(to_replace=character2int.keys(),value=character2int.values(),\n",
    "                               inplace=True)\n",
    "\n",
    "testing_data.replace(to_replace=character2int.keys(),value=character2int.values(),\n",
    "                     inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_true_train = to_categorical(y=training_data[\"label\"],num_classes=46)\n",
    "Y_true_test = to_categorical(y=testing_data[\"label\"],num_classes=46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.]], dtype=float32),\n",
       " array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.]], dtype=float32))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_true_test,Y_true_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78200, 46)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_true_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_dnn():\n",
    "\n",
    "    input_to_dnn = Input(shape=(1024,))\n",
    "    first_dense_out = Dense(units=1024,activation=\"relu\")(input_to_dnn)\n",
    "    second_dense_out = Dense(units=1024,activation=\"relu\")(first_dense_out)\n",
    "    second_dense_out = BatchNormalization()(second_dense_out)\n",
    "    output = Dense(units=46,activation=\"softmax\")(second_dense_out)\n",
    "\n",
    "    return Model(inputs=[input_to_dnn],outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_data_generator(data_df,Y_true,mb_size):\n",
    "    \n",
    "    for time_step in range(data_df.shape[0]//mb_size):\n",
    "        X_mb = list()\n",
    "        for img_path in data_df.iloc[time_step*mb_size:(time_step+1)*mb_size,0]:\n",
    "            img_np_array = plt.imread(img_path)\n",
    "            reshaped_np_array = img_np_array.reshape(1024,)\n",
    "            X_mb.append(reshaped_np_array)\n",
    "        X_mb = np.array(X_mb)\n",
    "        Y_true_mb = Y_true[time_step*mb_size:(time_step+1)*mb_size]\n",
    "        \n",
    "        yield X_mb, Y_true_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "training_data_mb_size = 782\n",
    "testing_data_mb_size = 138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1024)]            0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 1024)              4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 46)                47150     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2150446 (8.20 MB)\n",
      "Trainable params: 2148398 (8.20 MB)\n",
      "Non-trainable params: 2048 (8.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = multiclass_dnn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(Y_true_mb,Y_pred_mb):\n",
    "    return tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_true=Y_true_mb,y_pred=Y_pred_mb))\n",
    "optimizer = SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def training_step(X_train_mb,Y_true_train_mb):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "            \n",
    "        Y_pred_train_mb = model(X_train_mb, training=True)\n",
    "        training_loss = loss_fn(Y_true_train_mb, Y_pred_train_mb)\n",
    "\n",
    "    grads = tape.gradient(training_loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "    train_acc_metric.update_state(Y_true_train_mb,Y_pred_train_mb)\n",
    "\n",
    "    return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def testing_forward_pass(X_test_mb,Y_true_test_mb):\n",
    "\n",
    "    Y_pred_test_mb = model(X_test_mb,training=False)\n",
    "    testing_loss = loss_fn(Y_true_test_mb,Y_pred_test_mb)\n",
    "    test_acc_metric.update_state(Y_true_test_mb,Y_pred_test_mb)\n",
    "\n",
    "    return testing_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time Step 50, Training loss for one mini batch: 4.3327\n",
      "Epoch 1, Time Step 100, Training loss for one mini batch: 4.2772\n",
      "Epoch 1, Training Accuracy: 0.03\n",
      "\n",
      "Epoch 1, Testing Loss for last mini batch: 4.0263\n",
      "Epoch 1, Testing Accuracy: 0.12\n",
      "\n",
      "\n",
      "\n",
      "Epoch 2, Time Step 50, Training loss for one mini batch: 4.1985\n",
      "Epoch 2, Time Step 100, Training loss for one mini batch: 4.1998\n",
      "Epoch 2, Training Accuracy: 0.07\n",
      "\n",
      "Epoch 2, Testing Loss for last mini batch: 3.8732\n",
      "Epoch 2, Testing Accuracy: 0.20\n",
      "\n",
      "\n",
      "\n",
      "Epoch 3, Time Step 50, Training loss for one mini batch: 4.1527\n",
      "Epoch 3, Time Step 100, Training loss for one mini batch: 4.1578\n",
      "Epoch 3, Training Accuracy: 0.09\n",
      "\n",
      "Epoch 3, Testing Loss for last mini batch: 3.7261\n",
      "Epoch 3, Testing Accuracy: 0.25\n",
      "\n",
      "\n",
      "\n",
      "Epoch 4, Time Step 50, Training loss for one mini batch: 4.1278\n",
      "Epoch 4, Time Step 100, Training loss for one mini batch: 4.1317\n",
      "Epoch 4, Training Accuracy: 0.11\n",
      "\n",
      "Epoch 4, Testing Loss for last mini batch: 3.6139\n",
      "Epoch 4, Testing Accuracy: 0.28\n",
      "\n",
      "\n",
      "\n",
      "Epoch 5, Time Step 50, Training loss for one mini batch: 4.1116\n",
      "Epoch 5, Time Step 100, Training loss for one mini batch: 4.1125\n",
      "Epoch 5, Training Accuracy: 0.13\n",
      "\n",
      "Epoch 5, Testing Loss for last mini batch: 3.4755\n",
      "Epoch 5, Testing Accuracy: 0.31\n",
      "\n",
      "\n",
      "\n",
      "Epoch 6, Time Step 50, Training loss for one mini batch: 4.0995\n",
      "Epoch 6, Time Step 100, Training loss for one mini batch: 4.0991\n",
      "Epoch 6, Training Accuracy: 0.14\n",
      "\n",
      "Epoch 6, Testing Loss for last mini batch: 3.3170\n",
      "Epoch 6, Testing Accuracy: 0.33\n",
      "\n",
      "\n",
      "\n",
      "Epoch 7, Time Step 50, Training loss for one mini batch: 4.0910\n",
      "Epoch 7, Time Step 100, Training loss for one mini batch: 4.0889\n",
      "Epoch 7, Training Accuracy: 0.15\n",
      "\n",
      "Epoch 7, Testing Loss for last mini batch: 3.1478\n",
      "Epoch 7, Testing Accuracy: 0.34\n",
      "\n",
      "\n",
      "\n",
      "Epoch 8, Time Step 50, Training loss for one mini batch: 4.0839\n",
      "Epoch 8, Time Step 100, Training loss for one mini batch: 4.0806\n",
      "Epoch 8, Training Accuracy: 0.16\n",
      "\n",
      "Epoch 8, Testing Loss for last mini batch: 2.9966\n",
      "Epoch 8, Testing Accuracy: 0.36\n",
      "\n",
      "\n",
      "\n",
      "Epoch 9, Time Step 50, Training loss for one mini batch: 4.0781\n",
      "Epoch 9, Time Step 100, Training loss for one mini batch: 4.0734\n",
      "Epoch 9, Training Accuracy: 0.17\n",
      "\n",
      "Epoch 9, Testing Loss for last mini batch: 2.8933\n",
      "Epoch 9, Testing Accuracy: 0.37\n",
      "\n",
      "\n",
      "\n",
      "Epoch 10, Time Step 50, Training loss for one mini batch: 4.0731\n",
      "Epoch 10, Time Step 100, Training loss for one mini batch: 4.0670\n",
      "Epoch 10, Training Accuracy: 0.18\n",
      "\n",
      "Epoch 10, Testing Loss for last mini batch: 2.8138\n",
      "Epoch 10, Testing Accuracy: 0.38\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "test_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    training_data_generator = custom_data_generator(training_data,Y_true_train,782)\n",
    "\n",
    "    for time_step, (X_train_mb, Y_true_train_mb) in enumerate(training_data_generator):\n",
    "        training_loss = training_step(X_train_mb,Y_true_train_mb)\n",
    "\n",
    "        if (time_step+1) % 50 == 0:\n",
    "            print(\"Epoch %d, Time Step %d, Training loss for one mini batch: %.4f\"\n",
    "            % (epoch+1, time_step+1, float(training_loss)))\n",
    "            \n",
    "    training_acc = train_acc_metric.result()    \n",
    "    print(\"Epoch %d, Training Accuracy: %.2f\" % (epoch+1,float(training_acc)))\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    testing_data_generator = custom_data_generator(testing_data,Y_true_test,testing_data_mb_size)\n",
    "\n",
    "    for X_test_mb, Y_true_test_mb in testing_data_generator:\n",
    "        testing_loss = testing_forward_pass(X_test_mb,Y_true_test_mb)\n",
    "\n",
    "    print(\"\\nEpoch %d, Testing Loss for last mini batch: %.4f\" % (epoch+1,float(testing_loss)))\n",
    "    testing_acc = test_acc_metric.result()\n",
    "    print(\"Epoch %d, Testing Accuracy: %.2f\" % (epoch+1,float(testing_acc)))\n",
    "    test_acc_metric.reset_states()\n",
    "\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time Step 50, Training loss for one mini batch: 3.9041\n",
      "Epoch 1, Time Step 100, Training loss for one mini batch: 3.7783\n",
      "Epoch 1, Training Accuracy: 0.00\n",
      "\n",
      "Epoch 1, Testing Loss for last mini batch: 2.4000\n",
      "Epoch 1, Testing Accuracy: 0.00\n",
      "\n",
      "\n",
      "\n",
      "Epoch 2, Time Step 50, Training loss for one mini batch: 3.7531\n",
      "Epoch 2, Time Step 100, Training loss for one mini batch: 3.6773\n",
      "Epoch 2, Training Accuracy: 0.00\n",
      "\n",
      "Epoch 2, Testing Loss for last mini batch: 2.2709\n",
      "Epoch 2, Testing Accuracy: 0.00\n",
      "\n",
      "\n",
      "\n",
      "Epoch 3, Time Step 50, Training loss for one mini batch: 3.7403\n",
      "Epoch 3, Time Step 100, Training loss for one mini batch: 3.6417\n",
      "Epoch 3, Training Accuracy: 0.00\n",
      "\n",
      "Epoch 3, Testing Loss for last mini batch: 2.2307\n",
      "Epoch 3, Testing Accuracy: 0.00\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Training phase\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     training_data_generator \u001b[38;5;241m=\u001b[39m custom_data_generator(training_data, Y_true_train, \u001b[38;5;241m782\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m time_step, (X_train_mb, Y_true_train_mb) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(training_data_generator):\n\u001b[1;32m     10\u001b[0m         training_loss \u001b[38;5;241m=\u001b[39m training_step(X_train_mb, Y_true_train_mb)\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (time_step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m50\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[34], line 7\u001b[0m, in \u001b[0;36mcustom_data_generator\u001b[0;34m(data_df, Y_true, mb_size)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_path \u001b[38;5;129;01min\u001b[39;00m data_df\u001b[38;5;241m.\u001b[39miloc[time_step\u001b[38;5;241m*\u001b[39mmb_size:(time_step\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mmb_size,\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m      6\u001b[0m     img_np_array \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mimread(img_path)\n\u001b[0;32m----> 7\u001b[0m     reshaped_np_array \u001b[38;5;241m=\u001b[39m \u001b[43mimg_np_array\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     X_mb\u001b[38;5;241m.\u001b[39mappend(reshaped_np_array)\n\u001b[1;32m      9\u001b[0m X_mb \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X_mb)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time Step 50, Training loss for one mini batch: 3.9082\n",
      "Epoch 1, Time Step 100, Training loss for one mini batch: 3.6615\n",
      "Epoch 1, Training Accuracy: 0.00\n",
      "\n",
      "Epoch 1, Testing Loss for last mini batch: 2.2392\n",
      "Epoch 1, Testing Accuracy: 0.00\n",
      "\n",
      "\n",
      "\n",
      "Epoch 2, Time Step 50, Training loss for one mini batch: 3.6818\n",
      "Epoch 2, Time Step 100, Training loss for one mini batch: 3.6356\n",
      "Epoch 2, Training Accuracy: 0.00\n",
      "\n",
      "Epoch 2, Testing Loss for last mini batch: 2.1477\n",
      "Epoch 2, Testing Accuracy: 0.00\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Training phase\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     training_data_generator \u001b[38;5;241m=\u001b[39m custom_data_generator(training_data, Y_true_train, \u001b[38;5;241m782\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m     \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_data_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# Testing phase\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     testing_data_generator \u001b[38;5;241m=\u001b[39m custom_data_generator(testing_data, Y_true_test, testing_data_mb_size)\n",
      "Cell \u001b[0;32mIn[46], line 6\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch, training_data_generator)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_one_epoch\u001b[39m(epoch, training_data_generator):\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m time_step, (X_train_mb, Y_true_train_mb) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(training_data_generator):\n\u001b[1;32m      7\u001b[0m         training_loss \u001b[38;5;241m=\u001b[39m training_step(X_train_mb, Y_true_train_mb)\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (time_step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m50\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[34], line 6\u001b[0m, in \u001b[0;36mcustom_data_generator\u001b[0;34m(data_df, Y_true, mb_size)\u001b[0m\n\u001b[1;32m      4\u001b[0m X_mb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_path \u001b[38;5;129;01min\u001b[39;00m data_df\u001b[38;5;241m.\u001b[39miloc[time_step\u001b[38;5;241m*\u001b[39mmb_size:(time_step\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mmb_size,\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m----> 6\u001b[0m     img_np_array \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     reshaped_np_array \u001b[38;5;241m=\u001b[39m img_np_array\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1024\u001b[39m,)\n\u001b[1;32m      8\u001b[0m     X_mb\u001b[38;5;241m.\u001b[39mappend(reshaped_np_array)\n",
      "File \u001b[0;32m~/aiml-projects/class-project/.venv/lib/python3.8/site-packages/matplotlib/pyplot.py:2195\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   2193\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(matplotlib\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimread)\n\u001b[1;32m   2194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimread\u001b[39m(fname, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 2195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmatplotlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/aiml-projects/class-project/.venv/lib/python3.8/site-packages/matplotlib/image.py:1564\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1559\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease open the URL for reading and pass the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult to Pillow, e.g. with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1562\u001b[0m         )\n\u001b[1;32m   1563\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m img_open(fname) \u001b[38;5;28;01mas\u001b[39;00m image:\n\u001b[0;32m-> 1564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43m_pil_png_to_float_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1565\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, PIL\u001b[38;5;241m.\u001b[39mPngImagePlugin\u001b[38;5;241m.\u001b[39mPngImageFile) \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m   1566\u001b[0m             pil_to_array(image))\n",
      "File \u001b[0;32m~/aiml-projects/class-project/.venv/lib/python3.8/site-packages/matplotlib/image.py:1743\u001b[0m, in \u001b[0;36m_pil_png_to_float_array\u001b[0;34m(pil_png)\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdivide(pil_png, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m4\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rawmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# Grayscale.\u001b[39;00m\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdivide\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpil_png\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rawmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI;16B\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# Grayscale.\u001b[39;00m\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdivide(pil_png, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m16\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/aiml-projects/class-project/.venv/lib/python3.8/site-packages/PIL/Image.py:742\u001b[0m, in \u001b[0;36mImage.__array_interface__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    740\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtobytes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 742\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, (\u001b[38;5;167;01mMemoryError\u001b[39;00m, \u001b[38;5;167;01mRecursionError\u001b[39;00m)):\n",
      "File \u001b[0;32m~/aiml-projects/class-project/.venv/lib/python3.8/site-packages/PIL/Image.py:802\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m encoder_args \u001b[38;5;241m==\u001b[39m ():\n\u001b[1;32m    800\u001b[0m     encoder_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[0;32m--> 802\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/aiml-projects/class-project/.venv/lib/python3.8/site-packages/PIL/ImageFile.py:293\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    292\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 293\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
