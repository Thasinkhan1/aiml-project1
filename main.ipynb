{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle as kg\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.layers import Input, Dense, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD,RMSprop,Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KAGGLE_USERNAME\"] = \"thasinkhan\"\n",
    "os.environ[\"KAGGLE_KEY\"] = \"d0e58b5e1972f61220788d36914159c2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.api.authenticate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/medahmedkrichen/devanagari-handwritten-character-datase\n"
     ]
    }
   ],
   "source": [
    "kg.api.dataset_download_files(dataset=\"medahmedkrichen/devanagari-handwritten-character-datase\",\n",
    "                              path=\"dataset\",unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_df(path):\n",
    "\n",
    "    img_path = list()\n",
    "    img_label = list()\n",
    "\n",
    "    for single_class_dir_path in pathlib.Path(path).glob(\"*\"):\n",
    "\n",
    "        for single_class_img_path in pathlib.Path(single_class_dir_path).glob(\"*.png\"):\n",
    "\n",
    "            img_path.append(str(single_class_img_path))\n",
    "            #print(str(single_class_img_path).split(\"/\")[-2].split(\"_\")[-1])\n",
    "            img_label.append(str(single_class_img_path).split(\"/\")[-2].split(\"_\")[-1])\n",
    "\n",
    "    return pd.DataFrame(data={\"img_path\":img_path,\"label\":img_label})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"dataset/DevanagariHandwrittenCharacterDataset/Train\"\n",
    "test_path = \"dataset/DevanagariHandwrittenCharacterDataset/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = train_test_df(train_path)\n",
    "testing_data = train_test_df(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((78200, 2), (13800, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape,testing_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset/DevanagariHandwrittenCharacterDataset/...</td>\n",
       "      <td>ra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset/DevanagariHandwrittenCharacterDataset/...</td>\n",
       "      <td>ra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset/DevanagariHandwrittenCharacterDataset/...</td>\n",
       "      <td>ra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset/DevanagariHandwrittenCharacterDataset/...</td>\n",
       "      <td>ra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset/DevanagariHandwrittenCharacterDataset/...</td>\n",
       "      <td>ra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path label\n",
       "0  dataset/DevanagariHandwrittenCharacterDataset/...    ra\n",
       "1  dataset/DevanagariHandwrittenCharacterDataset/...    ra\n",
       "2  dataset/DevanagariHandwrittenCharacterDataset/...    ra\n",
       "3  dataset/DevanagariHandwrittenCharacterDataset/...    ra\n",
       "4  dataset/DevanagariHandwrittenCharacterDataset/...    ra"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset/DevanagariHandwrittenCharacterDataset/...</td>\n",
       "      <td>ra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset/DevanagariHandwrittenCharacterDataset/...</td>\n",
       "      <td>ra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset/DevanagariHandwrittenCharacterDataset/...</td>\n",
       "      <td>ra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset/DevanagariHandwrittenCharacterDataset/...</td>\n",
       "      <td>ra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset/DevanagariHandwrittenCharacterDataset/...</td>\n",
       "      <td>ra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path label\n",
       "0  dataset/DevanagariHandwrittenCharacterDataset/...    ra\n",
       "1  dataset/DevanagariHandwrittenCharacterDataset/...    ra\n",
       "2  dataset/DevanagariHandwrittenCharacterDataset/...    ra\n",
       "3  dataset/DevanagariHandwrittenCharacterDataset/...    ra\n",
       "4  dataset/DevanagariHandwrittenCharacterDataset/...    ra"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ra', 'chha', 'patalosaw', 'dha', 'la', 'ga', 'yaw', 'na', '3',\n",
       "       'petchiryakha', 'pha', 'gya', 'da', 'kha', 'tha', '1', 'ja', '4',\n",
       "       'ma', 'motosaw', 'chhya', 'ha', '6', 'taamatar', '2', 'yna',\n",
       "       'adna', 'tra', 'kna', 'tabala', 'ba', 'waw', '7', 'pa', '0', 'jha',\n",
       "       'bha', 'daa', '9', '8', 'dhaa', 'gha', 'cha', 'thaa', 'ka', '5'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 46)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(len(training_data['label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "character2int = dict(zip(training_data[\"label\"].unique(),range(len(training_data[\"label\"].unique()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ra', 'chha', 'patalosaw', 'dha', 'la', 'ga', 'yaw', 'na', '3', 'petchiryakha', 'pha', 'gya', 'da', 'kha', 'tha', '1', 'ja', '4', 'ma', 'motosaw', 'chhya', 'ha', '6', 'taamatar', '2', 'yna', 'adna', 'tra', 'kna', 'tabala', 'ba', 'waw', '7', 'pa', '0', 'jha', 'bha', 'daa', '9', '8', 'dhaa', 'gha', 'cha', 'thaa', 'ka', '5'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character2int.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[\"label\"].replace(to_replace=character2int.keys(),value=character2int.values(),\n",
    "                               inplace=True)\n",
    "\n",
    "testing_data.replace(to_replace=character2int.keys(),value=character2int.values(),\n",
    "                     inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_true_train = to_categorical(y=training_data[\"label\"],num_classes=46)\n",
    "Y_true_test = to_categorical(y=testing_data[\"label\"],num_classes=46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.]], dtype=float32),\n",
       " array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.]], dtype=float32))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_true_test,Y_true_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78200, 46)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_true_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_dnn():\n",
    "\n",
    "    input_to_dnn = Input(shape=(1024,))\n",
    "    first_dense_out = Dense(units=1024,activation=\"relu\")(input_to_dnn)\n",
    "    second_dense_out = Dense(units=1024,activation=\"relu\")(first_dense_out)\n",
    "    second_dense_out = BatchNormalization()(second_dense_out)\n",
    "    output = Dense(units=46,activation=\"softmax\")(second_dense_out)\n",
    "\n",
    "    return Model(inputs=[input_to_dnn],outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_data_generator(data_df,Y_true,mb_size):\n",
    "    \n",
    "    for time_step in range(data_df.shape[0]//mb_size):\n",
    "        X_mb = list()\n",
    "        for img_path in data_df.iloc[time_step*mb_size:(time_step+1)*mb_size,0]:\n",
    "            img_np_array = plt.imread(img_path)\n",
    "            reshaped_np_array = img_np_array.reshape(1024,)\n",
    "            X_mb.append(reshaped_np_array)\n",
    "        X_mb = np.array(X_mb)\n",
    "        Y_true_mb = Y_true[time_step*mb_size:(time_step+1)*mb_size]\n",
    "        \n",
    "        yield X_mb, Y_true_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "training_data_mb_size = 782\n",
    "testing_data_mb_size = 138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1024)]            0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 1024)              4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 46)                47150     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2150446 (8.20 MB)\n",
      "Trainable params: 2148398 (8.20 MB)\n",
      "Non-trainable params: 2048 (8.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = multiclass_dnn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(Y_true_mb,Y_pred_mb):\n",
    "    return tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_true=Y_true_mb,y_pred=Y_pred_mb))\n",
    "optimizer = SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def training_step(X_train_mb,Y_true_train_mb):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "            \n",
    "        Y_pred_train_mb = model(X_train_mb, training=True)\n",
    "        training_loss = loss_fn(Y_true_train_mb, Y_pred_train_mb)\n",
    "\n",
    "    grads = tape.gradient(training_loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "    train_acc_metric.update_state(Y_true_train_mb,Y_pred_train_mb)\n",
    "\n",
    "    return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def testing_forward_pass(X_test_mb,Y_true_test_mb):\n",
    "\n",
    "    Y_pred_test_mb = model(X_test_mb,training=False)\n",
    "    testing_loss = loss_fn(Y_true_test_mb,Y_pred_test_mb)\n",
    "    test_acc_metric.update_state(Y_true_test_mb,Y_pred_test_mb)\n",
    "\n",
    "    return testing_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time Step 50, Training loss for one mini batch: 4.3327\n",
      "Epoch 1, Time Step 100, Training loss for one mini batch: 4.2772\n",
      "Epoch 1, Training Accuracy: 0.03\n",
      "\n",
      "Epoch 1, Testing Loss for last mini batch: 4.0263\n",
      "Epoch 1, Testing Accuracy: 0.12\n",
      "\n",
      "\n",
      "\n",
      "Epoch 2, Time Step 50, Training loss for one mini batch: 4.1985\n",
      "Epoch 2, Time Step 100, Training loss for one mini batch: 4.1998\n",
      "Epoch 2, Training Accuracy: 0.07\n",
      "\n",
      "Epoch 2, Testing Loss for last mini batch: 3.8732\n",
      "Epoch 2, Testing Accuracy: 0.20\n",
      "\n",
      "\n",
      "\n",
      "Epoch 3, Time Step 50, Training loss for one mini batch: 4.1527\n",
      "Epoch 3, Time Step 100, Training loss for one mini batch: 4.1578\n",
      "Epoch 3, Training Accuracy: 0.09\n",
      "\n",
      "Epoch 3, Testing Loss for last mini batch: 3.7261\n",
      "Epoch 3, Testing Accuracy: 0.25\n",
      "\n",
      "\n",
      "\n",
      "Epoch 4, Time Step 50, Training loss for one mini batch: 4.1278\n",
      "Epoch 4, Time Step 100, Training loss for one mini batch: 4.1317\n",
      "Epoch 4, Training Accuracy: 0.11\n",
      "\n",
      "Epoch 4, Testing Loss for last mini batch: 3.6139\n",
      "Epoch 4, Testing Accuracy: 0.28\n",
      "\n",
      "\n",
      "\n",
      "Epoch 5, Time Step 50, Training loss for one mini batch: 4.1116\n",
      "Epoch 5, Time Step 100, Training loss for one mini batch: 4.1125\n",
      "Epoch 5, Training Accuracy: 0.13\n",
      "\n",
      "Epoch 5, Testing Loss for last mini batch: 3.4755\n",
      "Epoch 5, Testing Accuracy: 0.31\n",
      "\n",
      "\n",
      "\n",
      "Epoch 6, Time Step 50, Training loss for one mini batch: 4.0995\n",
      "Epoch 6, Time Step 100, Training loss for one mini batch: 4.0991\n",
      "Epoch 6, Training Accuracy: 0.14\n",
      "\n",
      "Epoch 6, Testing Loss for last mini batch: 3.3170\n",
      "Epoch 6, Testing Accuracy: 0.33\n",
      "\n",
      "\n",
      "\n",
      "Epoch 7, Time Step 50, Training loss for one mini batch: 4.0910\n",
      "Epoch 7, Time Step 100, Training loss for one mini batch: 4.0889\n",
      "Epoch 7, Training Accuracy: 0.15\n",
      "\n",
      "Epoch 7, Testing Loss for last mini batch: 3.1478\n",
      "Epoch 7, Testing Accuracy: 0.34\n",
      "\n",
      "\n",
      "\n",
      "Epoch 8, Time Step 50, Training loss for one mini batch: 4.0839\n",
      "Epoch 8, Time Step 100, Training loss for one mini batch: 4.0806\n",
      "Epoch 8, Training Accuracy: 0.16\n",
      "\n",
      "Epoch 8, Testing Loss for last mini batch: 2.9966\n",
      "Epoch 8, Testing Accuracy: 0.36\n",
      "\n",
      "\n",
      "\n",
      "Epoch 9, Time Step 50, Training loss for one mini batch: 4.0781\n",
      "Epoch 9, Time Step 100, Training loss for one mini batch: 4.0734\n",
      "Epoch 9, Training Accuracy: 0.17\n",
      "\n",
      "Epoch 9, Testing Loss for last mini batch: 2.8933\n",
      "Epoch 9, Testing Accuracy: 0.37\n",
      "\n",
      "\n",
      "\n",
      "Epoch 10, Time Step 50, Training loss for one mini batch: 4.0731\n",
      "Epoch 10, Time Step 100, Training loss for one mini batch: 4.0670\n",
      "Epoch 10, Training Accuracy: 0.18\n",
      "\n",
      "Epoch 10, Testing Loss for last mini batch: 2.8138\n",
      "Epoch 10, Testing Accuracy: 0.38\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "test_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    training_data_generator = custom_data_generator(training_data,Y_true_train,782)\n",
    "\n",
    "    for time_step, (X_train_mb, Y_true_train_mb) in enumerate(training_data_generator):\n",
    "        training_loss = training_step(X_train_mb,Y_true_train_mb)\n",
    "\n",
    "        if (time_step+1) % 50 == 0:\n",
    "            print(\"Epoch %d, Time Step %d, Training loss for one mini batch: %.4f\"\n",
    "            % (epoch+1, time_step+1, float(training_loss)))\n",
    "            \n",
    "    training_acc = train_acc_metric.result()    \n",
    "    print(\"Epoch %d, Training Accuracy: %.2f\" % (epoch+1,float(training_acc)))\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    testing_data_generator = custom_data_generator(testing_data,Y_true_test,testing_data_mb_size)\n",
    "\n",
    "    for X_test_mb, Y_true_test_mb in testing_data_generator:\n",
    "        testing_loss = testing_forward_pass(X_test_mb,Y_true_test_mb)\n",
    "\n",
    "    print(\"\\nEpoch %d, Testing Loss for last mini batch: %.4f\" % (epoch+1,float(testing_loss)))\n",
    "    testing_acc = test_acc_metric.result()\n",
    "    print(\"Epoch %d, Testing Accuracy: %.2f\" % (epoch+1,float(testing_acc)))\n",
    "    test_acc_metric.reset_states()\n",
    "\n",
    "    print(\"\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
